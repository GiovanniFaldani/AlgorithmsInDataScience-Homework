{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebeaac9-5dbb-4093-bb06-597d616c1819",
   "metadata": {},
   "source": [
    "<font size=5  color=#003366> [LINMA2472] - Algorithms in Data Science <br>\n",
    "Project 1: Networks </font> <br><br>\n",
    "<font size=3  color=#003366>  Students: Iacopo Canetta, Giovanni Faldani, Constance Nkweya Tofeun\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee9aae-32ac-4e40-89c6-8b8196a232ad",
   "metadata": {},
   "source": [
    "- <font size=4  color=#003366>Task 1: building the co-occurence network of characters </font> <br><br>\n",
    "In this project we'll build a graph network representing the bonds between characters present in the classical novel \"The Betrothed\" by Alessandro Manzoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15380d0-ca44-4edb-83c6-a70993a3c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd # useful dataframe support\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt # plot operations\n",
    "import networkx as nx # useful for network operations\n",
    "import nltk # useful for sentence parsing\n",
    "import re # regular expressions for text parsing and finding proper names\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import sklearn\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import communities.algorithms as comm\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5071d-f966-4633-9401-bf3cf10c6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text file parsing\n",
    "#txt_filename = \"./data/pg35155.txt\"\n",
    "txt_filename = \"./data/les_trois_mousquetaire.txt\"\n",
    "\n",
    "text = []\n",
    "with open(txt_filename, \"r\", encoding='utf-8') as input_f:\n",
    "    text = input_f.read()\n",
    "\n",
    "# split text by paragraph\n",
    "\n",
    "paragraphs = re.split(\"(?<!\\\")\\n\\n(?<!\\\")\", text)#\\n is the name for skipping to the next line\n",
    "print(\"The text is composed of {} paragraphs!\\n\".format(len(paragraphs)))\n",
    "\n",
    "# extract all individual sentences from a text\n",
    "def sentences_in(text):\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "    sentences = sent_detector.tokenize(text.strip())\n",
    "    return sentences\n",
    "\n",
    "# extract all the dialogue within quotations in a text\n",
    "def dialogue_in(text):\n",
    "    normalQuotes = re.findall('\"([^\"]*)\"', text)\n",
    "    directionalQuotes = re.findall('“([^”]*)”', text)\n",
    "    return normalQuotes + directionalQuotes\n",
    "\n",
    "# extract all words beginning with a capital letter in a text\n",
    "def proper_names_in(text):\n",
    "    return re.findall(\"[A-Z][a-z]+\", text)\n",
    "\n",
    "# test with a random paragraph\n",
    "n = 75\n",
    "\n",
    "print(paragraphs[n])\n",
    "dialogues = dialogue_in(paragraphs[n])\n",
    "sentences = sentences_in(paragraphs[n])\n",
    "names = proper_names_in(paragraphs[n])\n",
    "print(\"\\nParagraph {} is composed of {} sentences, {} dialogues and {} proper names\".format(\n",
    "    n, len(sentences), len(dialogues), len(names)))\n",
    "print(\"The first sentence is: \\n\", sentences[0])\n",
    "if(len(dialogues)!=0):\n",
    "    print(\"The first dialogue is: \\n\", dialogues[0])\n",
    "print(\"The first 'name' is: \\n\", names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a603f9d-5dbe-4699-bed1-b332a1ae6e12",
   "metadata": {},
   "source": [
    "- As we can see finding the proper names of characters is no easy task, so we decided to rely on a curated external list of characters to look for matches and build our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e389e-f24e-4505-8d35-266a612bca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's list all the proper names in the book. This might take a while...\n",
    "allNames = set(proper_names_in(text))\n",
    "print(allNames)\n",
    "# need to make a decision here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3500c8-ccb6-445a-b4d1-af19cfbe44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open character list\n",
    "#txt_filename = \"./data/CharacterList.txt\"\n",
    "txt_filename = \"./data/name_list.txt\"\n",
    "\n",
    "characterList = []\n",
    "with open(txt_filename, \"r\") as input_f:\n",
    "    characterList = input_f.read()\n",
    "\n",
    "#parsing characterlist and counting them\n",
    "mainCharacters = re.split(\"\\n\", characterList)\n",
    "totalCharacters = len(mainCharacters)\n",
    "print(mainCharacters)\n",
    "\n",
    "# making dictionary of associations {graph node : character}\n",
    "nodeCharacter = dict()\n",
    "for i in range(len(mainCharacters)):\n",
    "    nodeCharacter[i] = mainCharacters[i]\n",
    "    \n",
    "print(\"\\n Node associations: \", nodeCharacter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleans a list of characters !!!TODO eliminate duplicates\n",
    "def clean_names(characterList, mainCharacters):\n",
    "    for character in list(characterList):\n",
    "        if character not in mainCharacters:\n",
    "            characterList.remove(character)\n",
    "            \n",
    "    \n",
    "#iterate over cleant list and updates matrix (lamest optimization ever)\n",
    "def update_matrix(characterList, mainCharacters, matrix):\n",
    "    if len(characterList) < 2:\n",
    "        return\n",
    "    \n",
    "    for i in range(len(characterList)):\n",
    "        currentCharacterIndex = mainCharacters.index(characterList[i])\n",
    "        for j in range(len(characterList) - i - 1):\n",
    "            secondCharacterIndex = mainCharacters.index(characterList[j + i + 1])\n",
    "            matrix[currentCharacterIndex][secondCharacterIndex] += 1;\n",
    "            matrix[secondCharacterIndex][currentCharacterIndex] += 1;\n",
    "            \n",
    "            \n",
    "\n",
    "#matrix totalCharacters * totalCharacters initialized with all 0s\n",
    "adjacencyMatrix = [[0 for _ in range(totalCharacters)] for _ in range(totalCharacters)]\n",
    "\n",
    "#iterate over paragraphs and get proper names\n",
    "for i in range(len(paragraphs)):\n",
    "    paragraphCharacters = proper_names_in(paragraphs[i])\n",
    "    paragraphCharacters = list( dict.fromkeys(paragraphCharacters))\n",
    "    clean_names(paragraphCharacters, mainCharacters)\n",
    "    update_matrix(paragraphCharacters, mainCharacters, adjacencyMatrix)\n",
    "    \n",
    "print(adjacencyMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ff8a1-1b29-48f4-8edd-17273f3e574c",
   "metadata": {},
   "source": [
    "- Making the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76bf87-ab1f-429a-a399-047930d67222",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# add one node per character\n",
    "for i in range(len(mainCharacters)):\n",
    "    G.add_node(i, size = 1)\n",
    "    \n",
    "    \n",
    "# add node labels\n",
    "nx.set_node_attributes(G, nodeCharacter, name='Names')\n",
    "\n",
    "# add the edges from the adjacency matrix (avoid duplicates)\n",
    "\n",
    "for i in range(len(adjacencyMatrix)-1):\n",
    "    for j in range(i+1, len(adjacencyMatrix[0])):\n",
    "        if adjacencyMatrix[i][j] != 0 :\n",
    "            G.add_edge(i,j, weight = adjacencyMatrix[i][j])\n",
    "    \n",
    "    \n",
    "    \n",
    "print(nx.info(G))\n",
    "#print(G.nodes[0][\"\"])\n",
    "\n",
    "def print_graph(G):\n",
    "    g_draw = G\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    pos = nx.circular_layout(g_draw)\n",
    "    nx.draw(g_draw, pos, node_color='lightblue', edge_color='lightblue', node_size=50, labels = nx.get_node_attributes(G, 'Names'), with_labels = True, width=0.5)\n",
    "    \n",
    "    \n",
    "    \n",
    "print_graph(G)\n",
    "plt.savefig('./data/socialNetwork.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604c8a9-4c09-4610-9b40-395a06239e84",
   "metadata": {},
   "source": [
    "<font size=4> Preliminary observations about the graph: </font>\n",
    "\n",
    "- Graph shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ec328-f198-4cef-a185-9a950281ccf1",
   "metadata": {},
   "source": [
    "- Degree assortativity: disassortative network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98cec1-7897-4565-a383-cd50c6255124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  find_assortativity(graph):\n",
    "    return nx.degree_assortativity_coefficient(graph)\n",
    "\n",
    "assortativity = find_assortativity(G)\n",
    "print(assortativity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91925bef-f25a-4a3a-8d94-86ad6d15b35e",
   "metadata": {},
   "source": [
    "- Community detection with Louvain algorithm and Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6865a6-430b-4e50-a57f-ce36297bfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Louvain algorithm\n",
    "\n",
    "communities1 = nx_comm.louvain_communities(G)\n",
    "print(\"Louvain algo detected: \", communities1)\n",
    "\n",
    "# Spectral clustering\n",
    "\n",
    "#prepare the adjacency matrix\n",
    "npMat = np.array([np.array(row) for row in adjacencyMatrix])\n",
    "\"\"\"\n",
    "for i in range(npMat.shape[0]):\n",
    "    for j in range(npMat.shape[1]):\n",
    "        if npMat[i][j] != 0:\n",
    "            npMat[i][j] = 1\n",
    "\"\"\"\n",
    "# Compute Laplacian matrix and set k to the number of eigenvalues \"close\" to zero -> optmal k\n",
    "Laplacian = npMat.copy()\n",
    "\n",
    "# edges are only counted with weight 1 for the Laplacian\n",
    "\n",
    "for i in range(Laplacian.shape[0]):\n",
    "    for j in range(Laplacian.shape[1]):\n",
    "        if Laplacian[i][j] != 0:\n",
    "            Laplacian[i][j] = -1\n",
    "\n",
    "for i in range(len(Laplacian)):\n",
    "    Laplacian[i][i] = nx.degree(G, i)\n",
    "\n",
    "# there should be at least one ZERO eigenvalue, then k-1 eignevalues CLOSE to zero\n",
    "w,v = LA.eig(Laplacian)\n",
    "print(\"Laplacian eigenvalues : \", w)\n",
    "\n",
    "#for the three musketeers, it looks like there is 1 eigenvalue close or equal to zero\n",
    "k=1\n",
    "\n",
    "clustering = sklearn.cluster.SpectralClustering(n_clusters=k, assign_labels='discretize', random_state=0, affinity='precomputed_nearest_neighbors').fit(npMat)\n",
    "communities2 = clustering.labels_\n",
    "print(\"SKL Spectral Clustering algo detected communities with labels: \", communities2)\n",
    "\n",
    "# plot the communities\n",
    "def plot_louvain_comm(G, community_):\n",
    "    color_map = []\n",
    "    # color up to 10 communities\n",
    "    color_list = ['blue', 'green', 'red', 'yellow', 'purple', 'orange', 'cyan', 'brown', 'black', 'white']\n",
    "    for node in G:\n",
    "        for i in range(len(community_)):\n",
    "            if node in community_[i]:\n",
    "                color_map.append(color_list[i])\n",
    "    \n",
    "    g_draw = G          \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    pos = nx.circular_layout(g_draw)\n",
    "    nx.draw(g_draw, pos, node_color=color_map, edge_color='lightblue', node_size=50, with_labels=True, width=0.5)\n",
    "    plt.savefig('./data/louvainCommunities.png',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectral_comm(G, community_):\n",
    "    color_map = []\n",
    "    # color up to 10 communities\n",
    "    color_list = ['blue', 'green', 'red', 'yellow', 'purple', 'orange', 'cyan', 'brown', 'black', 'white']\n",
    "    for i in range(len(G.nodes)):\n",
    "        color_map.append(color_list[community_[i]])\n",
    "    \n",
    "    g_draw = G          \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    pos = nx.circular_layout(g_draw)\n",
    "    nx.draw(g_draw, pos, node_color=color_map, edge_color='lightblue', node_size=50, with_labels=True, width=0.5)\n",
    "    plt.savefig('./data/spectralCommunities.png',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Plot of louvain communities:\")\n",
    "plot_louvain_comm(G, communities1)\n",
    "\n",
    "\n",
    "print(\"Plot of spectral communities:\")\n",
    "plot_spectral_comm(G, communities2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1652a-5d05-4cc4-8496-9e6646746eb4",
   "metadata": {},
   "source": [
    "- Comparison of the two methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d965cfa-978a-496f-b44d-691743be31f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74cbdfb9-bc15-466d-8ed5-5f34f9729120",
   "metadata": {},
   "source": [
    "<font size=4> Influence maximization problem </font>\n",
    "\n",
    "IC model from: https://github.com/AdnanRasad/Influence-Maximization-Analysis/blob/master/Kempe-Independent-Cascades-Model/IC-Graph:Networkx-Python\n",
    "\n",
    "tuple to list: https://stackoverflow.com/questions/12142133/how-to-get-first-element-in-a-list-of-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2502c9-72ce-4daa-9349-3b1f8e3ecc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = int(G.number_of_nodes() * 0.05)\n",
    "\n",
    "k = 3\n",
    "\n",
    "print(k)\n",
    "\n",
    "# simulates Num_of_Simulations loops of Independent Cascade\n",
    "def IC(Networkx_Graph,Seed_Set,Probability,Num_of_Simulations):\n",
    "    spread = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(Num_of_Simulations):\n",
    "        Y.append([])\n",
    "        Y[i].append(len(Seed_Set) / len(G.nodes))\n",
    "        new_active, Ans = Seed_Set[:], Seed_Set[:]\n",
    "        while new_active:\n",
    "            #Getting neighbour nodes of newly activate node\n",
    "            targets = Neighbour_finder(Networkx_Graph,Probability,new_active)\n",
    "    \n",
    "            #Calculating if any nodes of those neighbours can be activated, if yes add them to new_ones.\n",
    "            np.random.seed(i)\n",
    "            success = np.random.uniform(0,1,len(targets)) < Probability\n",
    "            new_ones = list(np.extract(success, sorted(targets)))\n",
    "            \n",
    "            #Checking which ones in new_ones are not in our Ans...only adding them to our Ans so that no duplicate in Ans.\n",
    "            new_active = list(set(new_ones) - set(Ans))\n",
    "            Ans += new_active\n",
    "            infOverTot = len(Ans) / len(G.nodes)\n",
    "            Y[i].append(infOverTot)\n",
    "        \n",
    "        spread.append(len(Ans))\n",
    "    \n",
    "    maxRowLenght = Max_Row_Len(Y)\n",
    "    Even_Rows(Y, maxRowLenght)\n",
    "    return(np.mean(spread), Y, np.std(spread))\n",
    "      \n",
    "\n",
    "#finds all the neighbors available for a set of nodes\n",
    "def Neighbour_finder(g,p,new_active):\n",
    "    \n",
    "    targets = []\n",
    "    for node in new_active:\n",
    "        targets += g.neighbors(node)\n",
    "\n",
    "    return(targets)\n",
    "\n",
    "\n",
    "#returns the max len among the rows\n",
    "def Max_Row_Len(listOfLists):\n",
    "    lenghts = []\n",
    "    \n",
    "    for i in range(len(listOfLists)):\n",
    "        lenghts.append(len(listOfLists[i]))\n",
    "        \n",
    "    return max(lenghts)\n",
    "\n",
    "\n",
    "#Even the rows out appending the last element to get them maxLenght long\n",
    "def Even_Rows(listOfLists, maxLenght):    \n",
    "    for i in range(len(listOfLists)):\n",
    "        elementsToAdd = maxLenght - len(listOfLists[i])\n",
    "        currentLen = len(listOfLists[i])\n",
    "        lastIndex = max(currentLen - 1, 0)\n",
    "        lastElement = listOfLists[i][lastIndex]\n",
    "        \n",
    "        for j in range(elementsToAdd):\n",
    "            listOfLists[i].append(lastElement)\n",
    "        \n",
    "\n",
    "#TODO find an adequate influence function for a set of nodes A\n",
    "#Run IC a 'large' number of times to find realizations X_i (By 'large' I mean like 10 let's not make this take forever)\n",
    "#Compute probability for each realization X_i, still unclear on how to do that because the notes are vague af\n",
    "\n",
    "def Greedy_Influence_Maximization(G, k, Probability, Num_of_Simulations):\n",
    "    A0 = []\n",
    "    V = G.nodes\n",
    "    while(len(A0) < k):\n",
    "        availableNodes = V - A0\n",
    "        max = 0\n",
    "        for node in availableNodes:\n",
    "            value = IC(G, A0 + [node], Probability, Num_of_Simulations)[0]\n",
    "            if (value > max):\n",
    "                max = value\n",
    "                v = node\n",
    "        A0 = A0 + [v]\n",
    "    return A0\n",
    "\n",
    "maxInfluenceSet = Greedy_Influence_Maximization(G, k, Probability=0.5, Num_of_Simulations=4)\n",
    "\n",
    "print(maxInfluenceSet)\n",
    "\n",
    "#Compare runs if IC starting from MI set to other runs starting from k max degree nodes\n",
    "\n",
    "MI_spread = IC(G, maxInfluenceSet, Probability=0.5, Num_of_Simulations=5044)\n",
    "\n",
    "#Extract the set of 3 nodes of maximum degree\n",
    "maxDegSet = sorted(G.degree, key=lambda tup: tup[1], reverse=True)[:len(maxInfluenceSet)]\n",
    "maxDegSet = [i[0] for i in maxDegSet]\n",
    "\n",
    "MaxDegSpread = IC(G, maxDegSet, Probability=0.5, Num_of_Simulations=4)\n",
    "\n",
    "#print(MaxDegSpread)\n",
    "#print(MI_spread)\n",
    "\n",
    "def plot_maxinf_set(G, set_):\n",
    "    color_map = []\n",
    "    # color up to 10 communities\n",
    "    color_list = ['lightblue', 'red']\n",
    "    for node in G:\n",
    "        if node in set_:\n",
    "            color_map.append(color_list[1])\n",
    "        else:\n",
    "            color_map.append(color_list[0])\n",
    "    \n",
    "    g_draw = G          \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    pos = nx.circular_layout(g_draw)\n",
    "    nx.draw(g_draw, pos, node_color=color_map, edge_color='lightblue', node_size=50, with_labels=True, width=0.5)\n",
    "    \n",
    "\n",
    "    \n",
    "plot_maxinf_set(G, maxInfluenceSet)\n",
    "plt.savefig('./data/maxInfluenceSocial.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb1e79-c5b6-420d-9944-8922d4267387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MaxDegSpread[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f938b3-e6a2-496c-8112-a17009b6c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#makes the all the rows at the same lenght (evens out epochs for all the tests)\n",
    "maxRowLenght = max(len(MaxDegSpread[1][0]), len(MI_spread[1][0]))\n",
    "Even_Rows(MaxDegSpread[1], maxRowLenght)\n",
    "Even_Rows(MI_spread[1], maxRowLenght)\n",
    "\n",
    "#converts Y to numpy array\n",
    "yMiSpread = np.array(MI_spread[1])\n",
    "yMaxDegSpread = np.array(MaxDegSpread[1])\n",
    "\n",
    "yMiSpread = np.mean(yMiSpread, axis=0)\n",
    "yMaxDegSpread = np.mean(yMaxDegSpread, axis=0)\n",
    "\n",
    "\n",
    "#plot graph\n",
    "\n",
    "x = range(0, maxRowLenght)\n",
    "\n",
    "plt.plot(x, yMaxDegSpread, label = \"MaxDegSpread\")\n",
    "plt.plot(x, yMiSpread, label = \"MiSpread\")\n",
    "plt.legend()\n",
    "plt.savefig('./data/spreadGraph.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c8608-9c4c-4a32-9ed7-25bf2c372251",
   "metadata": {},
   "source": [
    "- Barabasi-Albert comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe10956-0a16-4f26-8098-47fffef87f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate graph with same number of nodes and average degree\n",
    "\n",
    "H = nx.barabasi_albert_graph(len(G.nodes), int(np.mean(G.degree)))\n",
    "\n",
    "print_graph(H)\n",
    "plt.savefig('./data/barb-alb-graph.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9f858-6bfb-4571-9d31-090249e865fb",
   "metadata": {},
   "source": [
    "Compute the Greedy Influence Maximization algorithm on the new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28129467-60ca-4a97-baa7-49c288bd62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BarbMaxInfluenceSet = Greedy_Influence_Maximization(H, k, Probability=0.5, Num_of_Simulations=4)\n",
    "print(BarbMaxInfluenceSet)\n",
    "\n",
    "\n",
    "plot_maxinf_set(H, BarbMaxInfluenceSet)\n",
    "plt.savefig('./data/barbMaxInfluenceSocial.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147473a-89cb-4e5a-a6ab-580ffafc1232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
