{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e3a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note Grakel does not seem to support Python >=3.10, Python 3.9 works fine\n",
    "# you are free to remove imports that are not useful for you\n",
    "from grakel.datasets import fetch_dataset\n",
    "from grakel.kernels import WeisfeilerLehman, VertexHistogram\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import KernelPCA # to check your own implementation\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195a11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "edge list:  {(3, 4), (4, 3), (5, 4), (12, 13), (5, 7), (14, 13), (8, 9), (9, 8), (9, 14), (17, 15), (10, 9), (1, 6), (13, 14), (6, 5), (15, 17), (4, 5), (14, 9), (5, 6), (9, 10), (1, 2), (10, 11), (2, 1), (11, 10), (6, 1), (15, 13), (15, 16), (13, 15), (16, 15), (3, 2), (12, 11), (4, 10), (8, 7), (10, 4), (2, 3), (11, 12), (13, 12), (7, 5), (7, 8)}\n",
      "node-label dictionary:  {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 1, 16: 2, 17: 2}\n"
     ]
    }
   ],
   "source": [
    "# Some datasets, more datasets here https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets\n",
    "\n",
    "\"\"\"\n",
    "    The MUTAG dataset consists of 188 chemical compounds divided into two \n",
    "    classes according to their mutagenic effect on a bacterium. \n",
    "\n",
    "    The chemical data was obtained form http://cdb.ics.uci.edu and converted \n",
    "    to graphs, where vertices represent atoms and edges represent chemical \n",
    "    bonds. Explicit hydrogen atoms have been removed and vertices are labeled\n",
    "    by atom type and edges by bond type (single, double, triple or aromatic).\n",
    "    Chemical data was processed using the Chemistry Development Kit (v1.4).\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    ENZYMES is a dataset of protein tertiary structures obtained from (Borgwardt et al., 2005) \n",
    "    consisting of 600 enzymes from the BRENDA enzyme database (Schomburg et al., 2004). \n",
    "    In this case the task is to correctly assign each enzyme to one of the 6 EC top-level \n",
    "    classes. \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    NCI1 and NCI109 represent two balanced subsets of datasets of chemical compounds screened \n",
    "    for activity against non-small cell lung cancer and ovarian cancer cell lines respectively\n",
    "    (Wale and Karypis (2006) and http://pubchem.ncbi.nlm.nih.gov).\n",
    "\"\"\"\n",
    "\n",
    "dataset = fetch_dataset(\"MUTAG\", verbose=False) # just replace by the name of the datasets you want \"ENZYMES\", \"NCI1\"\n",
    "G = dataset.data\n",
    "y = dataset.target\n",
    "print(len(G))\n",
    "print(\"edge list: \", G[0][0])\n",
    "print(\"node-label dictionary: \", G[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2b4b-cf0f-4072-b4f9-606bd92a0719",
   "metadata": {},
   "source": [
    "- Task 1: computing the pairwise kernels of all the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61d97cd-686b-4e94-a8fb-f02de07a416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 188)\n",
      "[[507 210 206 ... 189 473 289]\n",
      " [210 263 145 ... 126 260 181]\n",
      " [206 145 263 ... 129 256 186]\n",
      " ...\n",
      " [189 126 129 ... 228 231 179]\n",
      " [473 260 256 ... 231 859 361]\n",
      " [289 181 186 ... 179 361 396]]\n",
      "The WL tree kernel matrix has rank 175\n"
     ]
    }
   ],
   "source": [
    "# compute WL kernel for all graph pairs\n",
    "\n",
    "H = 10 # number of iterations\n",
    "\n",
    "G_cutoff = []\n",
    "for i in range(len(G)):\n",
    "    G_cutoff.append(G[i][:2]) # ignore edge labels\n",
    "\n",
    "WLkernel = WeisfeilerLehman(n_iter = H) # default base graph kernel is VertexHistogram\n",
    "kernel = WLkernel.fit_transform(G_cutoff)\n",
    "print(kernel.shape)\n",
    "print(kernel)\n",
    "print(\"The WL tree kernel matrix has rank\", np.linalg.matrix_rank(kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39474665-fc1b-466b-a361-f0103c4fb5e1",
   "metadata": {},
   "source": [
    "If we try to think of the explicit embedding space for the WL subtree kernel, it's quite easy to notice how each cell of the kernel matrix is computed as $k_{WL}(G_1,G_2) = \\sum_{h=0}^{H} k_{VH}(G_1^h,G_2^h)$ , with $k_{VH}(G_1,G_2) = \\sum_{i \\in V_1} \\sum_{j \\in V_2} label(i) == label(j)$. The VertexHistogram kernel embeds each graph into a vector space of dimension equal to its number of vertices, so let's consider the graph with the maximum number of vertices $G'$ and say it has $V_{max}$ vertices, embedded into an array of dimension $V_{max}$ where every element is the label of node $i \\in \\{1, V_{max}\\}$. Every other graph can also be expressed as a $V_{max}$ dimensional array where the extra vertices will contain a non-valid label.\n",
    "The WL kernel will just contain $H$ iterations of this representation, which can be represented in a single array of dimension $H * V_{max}$, this being our explicit embedding space dimension.\n",
    "\n",
    "Considering the rank of the $K_{WL}$ matrix, we can extrapolate ????????? So the lower bound on the dimension of this implicit embedding space for $H=10$ is $10 * V_{max}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e35bc-ffee-4bed-acbc-b0850a6e0dee",
   "metadata": {},
   "source": [
    "- Task 2: kernel visualization, PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ebd4790-6f99-49d1-8c7c-5db618cdcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "# compute centered kernel\n",
    "N = kernel.shape[0]\n",
    "oneN = np.ones((N,N)) / N\n",
    "kernCenter = kernel - np.matmul(oneN, kernel) - np.matmul(kernel, oneN) + np.matmul(oneN, np.matmul(kernel, oneN))\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(kernCenter)\n",
    "# sort eigenvalues and vectors\n",
    "idx = np.argsort(eigenvalues)\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:,idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e6e5e5e-6021-4cd0-bfa8-3e5695516166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         18.70828693 18.92088793 ... 18.89444363 20.49390153\n",
      "  18.02775638]\n",
      " [18.70828693  0.         15.3622915  ... 15.45962483 24.53568829\n",
      "  17.23368794]\n",
      " [18.92088793 15.3622915   0.         ... 15.26433752 24.69817807\n",
      "  16.94107435]\n",
      " ...\n",
      " [18.89444363 15.45962483 15.26433752 ...  0.         25.\n",
      "  16.30950643]\n",
      " [20.49390153 24.53568829 24.69817807 ... 25.          0.\n",
      "  23.08679276]\n",
      " [18.02775638 17.23368794 16.94107435 ... 16.30950643 23.08679276\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Compute pairwise distances of graphs\n",
    "\n",
    "dists = np.zeros((N,N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        dists[i, j] = math.sqrt(kernel[i][i] + kernel[j][j] - 2*kernel[i][j])\n",
    "        \n",
    "print(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95ef2416-c406-496e-9d2f-50a66759b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# t-SNE representation\n",
    "\n",
    "tSNE = TSNE(n_components=2, perplexity=10, n_iter=1000)\n",
    "tSNE_embeddings = tSNE.fit_transform(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63708ef7-c880-4631-a086-ddde13b1efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison.... plot embeddings with PCA nad tSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76fb14-c132-4a9a-8509-12393fcbc3ad",
   "metadata": {},
   "source": [
    "- Task 3: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc40575c-518d-4f33-b882-259dee1cf318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6648936170212766\n"
     ]
    }
   ],
   "source": [
    "# 1 baseline (constant model accuracy)\n",
    "most_freq_y = max(set(y), key=list(y).count)\n",
    "naiveAccuracy = list(y == most_freq_y).count(True)/N\n",
    "print(naiveAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea6b3ab4-d7b0-4b3b-96c6-5cb907c24999",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      5\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e2\u001b[39m, kernel \u001b[38;5;241m=\u001b[39m WeisfeilerLehman(n_iter \u001b[38;5;241m=\u001b[39m H))\n\u001b[1;32m----> 7\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m prediction \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(data_test)\n\u001b[0;32m      9\u001b[0m score \u001b[38;5;241m=\u001b[39m accuracy_score(label_test, prediction)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:173\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    171\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    184\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    185\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    186\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1070\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1068\u001b[0m     )\n\u001b[1;32m-> 1070\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1086\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1088\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:852\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    850\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 852\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    856\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'set'"
     ]
    }
   ],
   "source": [
    "# 2 SVM model\n",
    "data_train, data_test, label_train, label_test = train_test_split(G_cutoff, y, test_size=0.2, train_size=0.8)\n",
    "H = 3\n",
    "\n",
    "svm_model = SVC(C = 1e2, kernel = WeisfeilerLehman(n_iter = H))\n",
    "\n",
    "svm_model.fit(data_train, label_train)\n",
    "prediction = svm_model.predict(data_test)\n",
    "score = accuracy_score(label_test, prediction)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f2472-d18b-4c61-92cb-5cc0aa19fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 hyperparameter selection with GridSearch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
